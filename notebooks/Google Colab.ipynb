{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3398,"status":"ok","timestamp":1720274941259,"user":{"displayName":"Christos Ioannidis","userId":"03422655750413322333"},"user_tz":-60},"id":"zE0HKl_TFH9N","outputId":"6277984e-5c95-43bd-ae30-72ba5b715e73"},"outputs":[],"source":["import os\n","try:\n","    from google.colab import drive\n","    drive.mount(\"/content/gdrive\", force_remount=True)\n","    # cd gdrive/MyDrive/'Colab Notebooks'/Innovative-Approaches-to-Asset-Prediction/\n","    os.chdir(\"/content/gdrive/MyDrive/'Colab Notebooks'/Innovative-Approaches-to-Asset-Prediction/\")\n","    print(\"Working on Google Colab...\")\n","except:\n","    os.chdir(\"../\")\n","    print(\"Working on local machine...\")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":18653,"status":"ok","timestamp":1720274959910,"user":{"displayName":"Christos Ioannidis","userId":"03422655750413322333"},"user_tz":-60},"id":"krlsUB3HFH9R","outputId":"0e9408e9-ecdc-4936-8538-5901938b2418"},"outputs":[],"source":["# !pip install -r requirements.txt"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"elapsed":3034,"status":"ok","timestamp":1720274962939,"user":{"displayName":"Christos Ioannidis","userId":"03422655750413322333"},"user_tz":-60},"id":"UzBmUOotMHip","outputId":"9896acf2-37b5-44f8-e83e-073e3afd57c6"},"outputs":[],"source":["import torch\n","import random\n","import numpy as np\n","import pandas as pd\n","\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torch.optim as optim\n","from torch.utils.data import Dataset, DataLoader\n","\n","import torchvision\n","from torchvision import transforms\n","\n","import matplotlib.pyplot as plt\n","from livelossplot import PlotLosses"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":8,"status":"ok","timestamp":1720274962940,"user":{"displayName":"Christos Ioannidis","userId":"03422655750413322333"},"user_tz":-60},"id":"8NGRFdEfMSMX"},"outputs":[],"source":["def set_seed(seed):\n","    \"\"\"\n","    Use this to set ALL the random seeds to a fixed value and take out any randomness from cuda kernels\n","    \"\"\"\n","    random.seed(seed)\n","    np.random.seed(seed)\n","    torch.manual_seed(seed)\n","    torch.cuda.manual_seed_all(seed)\n","    torch.backends.cudnn.benchmark = False  ##uses the inbuilt cudnn auto-tuner to find the fastest convolution algorithms. -\n","    torch.backends.cudnn.enabled = False\n","    return True"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["print(torch.version.cuda)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5,"status":"ok","timestamp":1720274962940,"user":{"displayName":"Christos Ioannidis","userId":"03422655750413322333"},"user_tz":-60},"id":"GA0ElmXzFsh-","outputId":"fb819818-0fa8-4e0a-cc07-a5394bed89b8"},"outputs":[],"source":["set_seed(42)\n","\n","device = 'cpu'\n","if torch.cuda.device_count() > 0 and torch.cuda.is_available():\n","    print(\"Cuda installed! Running on GPU!\")\n","    device = 'cuda'\n","else:\n","    print(\"No GPU available! Using CPU!\")"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":5,"status":"ok","timestamp":1720274966211,"user":{"displayName":"Christos Ioannidis","userId":"03422655750413322333"},"user_tz":-60},"id":"GkcD8eT8OAFx"},"outputs":[],"source":["# Custom dataset to handle image and target loading\n","class ImageDataset(Dataset):\n","    def __init__(self, images, targets, transform=None):\n","        self.images = images\n","        self.targets = targets\n","        self.transform = transform\n","\n","    def __len__(self):\n","        return len(self.images)\n","\n","    def __getitem__(self, idx):\n","        image = self.images[idx]\n","        target = self.targets[idx]\n","\n","        if self.transform:\n","            image = self.transform(image)\n","\n","        return image, target"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":243,"status":"ok","timestamp":1720279737884,"user":{"displayName":"Christos Ioannidis","userId":"03422655750413322333"},"user_tz":-60},"id":"ul9xbqYaOCma","outputId":"02b5b3b5-18cb-4a12-b368-396057c14cd0"},"outputs":[],"source":["full_data = np.load(\"./data/processed/SP500.EURUSD.USTREASURYINDEX.2014.2023/data.npy\", allow_pickle=True)   # noqa\n","print(full_data.shape)\n","# data = full_data\n","data = full_data[:400]\n","print(data[:1, :])"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def train_val_test_split(data, train_size=0.7, val_size=0.2):\n","    train_size = int(len(data) * train_size)\n","    val_size = int(len(data) * val_size)\n","    test_size = len(data) - train_size - val_size\n","    train_data = data[:train_size]\n","    val_data = data[train_size:train_size + val_size]\n","    test_data = data[train_size + val_size:]\n","    return train_data, val_data, test_data"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":254,"status":"ok","timestamp":1720279740181,"user":{"displayName":"Christos Ioannidis","userId":"03422655750413322333"},"user_tz":-60},"id":"asiDi3HGO1a-","outputId":"9206c7d7-6518-4594-e464-64396f3006c5"},"outputs":[],"source":["train_data, val_data, test_data = train_val_test_split(data)\n","\n","print(train_data.shape)\n","print(val_data.shape)\n","print(test_data.shape)\n","\n","train_images = train_data[:, 0]\n","train_targets = np.asarray(train_data[:, 1:], dtype=np.float32)\n","\n","val_images = val_data[:, 0]\n","val_targets = np.asarray(val_data[:, 1:], dtype=np.float32)\n","\n","test_images = test_data[:, 0]\n","test_targets = np.asarray(test_data[:, 1:], dtype=np.float32)\n","\n","print(train_images[0])\n","print(train_targets[0])"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":257,"status":"ok","timestamp":1720279743029,"user":{"displayName":"Christos Ioannidis","userId":"03422655750413322333"},"user_tz":-60},"id":"19RIRliXV3N5"},"outputs":[],"source":["# Transformations for the images\n","transform = transforms.Compose([\n","    transforms.ToTensor(),  # Convert to tensor\n","    transforms.Normalize((0.5,), (0.5,))  # Normalize to [-1, 1]\n","])\n","\n","# Create datasets and dataloaders\n","trainset = ImageDataset(train_images, train_targets, transform=transform)\n","valset = ImageDataset(val_images, val_targets, transform=transform)\n","testset = ImageDataset(test_images, test_targets, transform=transform)\n","\n","trainloader = DataLoader(trainset, batch_size=8, shuffle=True)\n","valloader = DataLoader(valset, batch_size=8, shuffle=False)\n","testloader = DataLoader(testset, batch_size=8, shuffle=False)"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":285,"status":"ok","timestamp":1720279745762,"user":{"displayName":"Christos Ioannidis","userId":"03422655750413322333"},"user_tz":-60},"id":"Uckgm9R2VQxy"},"outputs":[],"source":["class Net(nn.Module):\n","    def __init__(self, leak=0.2, output_size=3, img_size=64):\n","        super(Net, self).__init__()\n","        self.img_size = img_size\n","\n","        # Convolutional layers for feature extraction\n","        self.conv1 = nn.Conv2d(1, 32, kernel_size=3, padding=1)  # 1 input channel for grayscale\n","        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n","        self.conv3 = nn.Conv2d(64, 128, kernel_size=3, padding=1)\n","        self.conv4 = nn.Conv2d(128, 256, kernel_size=3, padding=1)\n","        self.conv5 = nn.Conv2d(256, 512, kernel_size=3, padding=1)\n","        self.conv6 = nn.Conv2d(512, 256, kernel_size=3, padding=1)\n","        self.conv7 = nn.Conv2d(256, 128, kernel_size=3, padding=1)\n","        self.conv9 = nn.Conv2d(128, 16, kernel_size=3, padding=1)\n","        self.pool = nn.MaxPool2d(2, 2)\n","        self.leakyrelu = nn.LeakyReLU(negative_slope=leak)\n","        self.flatten = nn.Flatten()\n","\n","        # Compute the size of the flattened feature map after the convolutional layers\n","        self.feature_dim = self._calculate_feature_dim()\n","\n","        # Fully connected layers\n","        self.fc1 = nn.Linear(self.feature_dim, 128)\n","        self.fc2 = nn.Linear(128, output_size)\n","\n","    def _calculate_feature_dim(self):\n","        # Function to calculate the size of the feature map after all convolutional and pooling layers\n","        size = self.img_size\n","        size = self._conv_output_size(size, kernel_size=3, padding=1)  # conv1\n","        size = self.pool_output_size(size, kernel_size=2)  # pool1\n","        size = self._conv_output_size(size, kernel_size=3, padding=1)  # conv2\n","        size = self.pool_output_size(size, kernel_size=2)  # pool2\n","        size = self._conv_output_size(size, kernel_size=3, padding=1)  # conv3\n","        size = self._conv_output_size(size, kernel_size=3, padding=1)  # conv4\n","        size = self.pool_output_size(size, kernel_size=2)  # pool3\n","        size = self._conv_output_size(size, kernel_size=3, padding=1)  # conv9\n","        size = self.pool_output_size(size, kernel_size=2)  # pool4\n","\n","        return 16 * size * size\n","\n","    def _conv_output_size(self, input_size, kernel_size, stride=1, padding=0):\n","        return (input_size + 2 * padding - kernel_size) // stride + 1\n","\n","    def pool_output_size(self, input_size, kernel_size, stride=2):\n","        return input_size // kernel_size\n","\n","    def forward(self, xb):\n","        # Convolution layers\n","        xb = self.leakyrelu(self.conv1(xb))\n","        xb = self.pool(xb)\n","        xb = self.leakyrelu(self.conv2(xb))\n","        xb = self.pool(xb)\n","        xb = self.leakyrelu(self.conv3(xb))\n","        xb = self.leakyrelu(self.conv4(xb))\n","        xb = self.leakyrelu(self.conv5(xb))\n","        xb = self.leakyrelu(self.conv6(xb))\n","        xb = self.leakyrelu(self.conv7(xb))\n","        xb = self.pool(xb)\n","        xb = self.leakyrelu(self.conv9(xb))\n","        xb = self.pool(xb)\n","\n","        # Flatten the output for the fully connected layers\n","        xb = self.flatten(xb)\n","\n","        # Fully connected layers\n","        xb = self.leakyrelu(self.fc1(xb))\n","        xb = self.fc2(xb)\n","        return xb\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["class CustomLoss(nn.Module):\n","    def __init__(self, loss_function=nn.MSELoss()):\n","        super(CustomLoss, self).__init__()\n","        self.element_loss = loss_function\n","\n","    def forward(self, outputs, targets):\n","        loss = self.element_loss(outputs, targets)\n","        sum_penalty = torch.mean(torch.abs(torch.sum(outputs, dim=1)))\n","        return loss + sum_penalty"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def matplotlib_imshow(img, one_channel=False):\n","    if one_channel:\n","        img = img.mean(dim=0)\n","    img = img / 2 + 0.5     # unnormalize\n","    npimg = img.numpy()\n","    if one_channel:\n","        plt.imshow(npimg, cmap=\"Greys\")\n","    else:\n","        plt.imshow(np.transpose(npimg, (1, 2, 0)))"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# get some random training images\n","images, labels = trainloader.dataset[0]\n","\n","# create grid of images\n","img_grid = torchvision.utils.make_grid(images)\n","\n","# show images\n","matplotlib_imshow(img_grid, one_channel=True)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# helper function\n","def select_n_random(data, labels, n=100):\n","    '''\n","    Selects n random datapoints and their corresponding labels from a dataset\n","    '''\n","    assert len(data) == len(labels)\n","\n","    perm = torch.randperm(len(data))\n","    return data[perm][:n], labels[perm][:n]\n","\n","# select random images and their target indices\n","images, labels = select_n_random(trainset.images, trainset.targets)\n","\n","# plot images\n","plt.figure(figsize=(16, 6))\n","for i in range(8):\n","    plt.subplot(2, 4, i + 1)\n","    plt.imshow(images[i].squeeze(), cmap='gray')\n","    plt.title(labels[i])\n","    plt.axis('off')\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Initialize the model, loss function, and optimizer\n","model = Net(img_size=128).to(device)\n","criterion = CustomLoss(nn.MSELoss())\n","optimizer = optim.AdamW(model.parameters(), lr=0.003)\n","\n","def mean_absolute_error(pred, target):\n","    return torch.mean(torch.abs(pred - target))\n","\n","epochs = 30\n","best_val_loss = float('inf')\n","liveloss = PlotLosses()\n","\n","for epoch in range(epochs):\n","    logs = {}\n","    model.train()\n","    running_loss = 0.0\n","    running_mae = 0.0\n","\n","    for images, targets in trainloader:\n","        images, targets = images.to(device), targets.to(device)\n","\n","        optimizer.zero_grad()\n","        outputs = model(images)\n","        loss = criterion(outputs, targets)\n","        loss.backward()\n","        optimizer.step()\n","\n","        running_loss += loss.item() * images.size(0)\n","        running_mae += mean_absolute_error(outputs, targets).item() * images.size(0)\n","\n","    train_loss = running_loss / len(trainloader.dataset)\n","    train_mae = running_mae / len(trainloader.dataset)\n","    logs['loss'] = train_loss\n","    logs['mae'] = train_mae\n","\n","    # Validation\n","    model.eval()\n","    val_loss = 0.0\n","    val_mae = 0.0\n","    with torch.no_grad():\n","        for images, targets in valloader:\n","            images, targets = images.to(device), targets.to(device)\n","            outputs = model(images)\n","            loss = criterion(outputs, targets)\n","            val_loss += loss.item() * images.size(0)\n","            val_mae += mean_absolute_error(outputs, targets).item() * images.size(0)\n","\n","    val_loss = val_loss / len(valloader.dataset)\n","    val_mae = val_mae / len(valloader.dataset)\n","    logs['val_loss'] = val_loss\n","    logs['val_mae'] = val_mae\n","\n","    liveloss.update(logs)\n","    liveloss.send()\n","\n","    print(f\"Epoch {epoch + 1}/{epochs}, Train Loss: {train_loss:.4f}, Train MAE: {train_mae:.4f}, Validation Loss: {val_loss:.4f}, Validation MAE: {val_mae:.4f}\")\n","\n","    # Save the model if it has the best validation loss so far\n","    if val_loss < best_val_loss:\n","        best_val_loss = val_loss\n","        torch.save(model.state_dict(), './deep_learning/models/best_model.pth')\n","\n","print('Finished Training')\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":269,"status":"ok","timestamp":1720280097734,"user":{"displayName":"Christos Ioannidis","userId":"03422655750413322333"},"user_tz":-60},"id":"tOi4ZK6xVXIC","outputId":"d4cc7a78-d74b-4fb1-a234-cdae7c65b25d"},"outputs":[],"source":["# Load the best model\n","model.load_state_dict(torch.load('./deep_learning/models/best_model.pth'))\n","\n","# Example of testing the model with a new image\n","test_image = full_data[500, 0]\n","test_image_tensor = transform(test_image).unsqueeze(0)  # Add batch dimension\n","\n","model.eval()\n","with torch.no_grad():\n","    prediction = model(test_image_tensor.to(device))\n","    print(\"Predicted values:\", prediction.cpu().numpy())\n","\n","print(\"Actual values:\", full_data[500, 1:])\n"]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.1"}},"nbformat":4,"nbformat_minor":0}
